{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1a549d6d",
   "metadata": {},
   "source": [
    "## Connect to a database\n",
    "\n",
    "In order to get data from a database with pandas, you first need to be able to connect to one. In this exercise, you'll practice creating a database engine to manage connections to a database, data.db. To do this, you'll use sqlalchemy's create_engine() function.\n",
    "\n",
    "create_engine() needs a string URL to the database. For SQLite databases, that string consists of \"sqlite:///\", then the database file name.\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "Instructions:\n",
    "\n",
    "\n",
    "<li> Import the create_engine() function from sqlalchemy.</li>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e77bcacf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import sqlalchemy's create_engine() function\n",
    "from sqlalchemy import create_engine"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75e478dc",
   "metadata": {},
   "source": [
    "<li> Use create_engine() to make a database engine for data.db.</li>\n",
    "\n",
    "\n",
    "<li>Run the last line of code to show the names of the tables in the database.</li>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14f58f73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import sqlalchemy's create_engine() function\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "# Create the database engine\n",
    "engine = create_engine(\"sqlite:///data.db\")\n",
    "\n",
    "# View the tables in the database\n",
    "print(engine.table_names())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffc8d972",
   "metadata": {},
   "source": [
    "## Load entire tables\n",
    "\n",
    "In the last exercise, you saw that data.db has two tables. weather has historical weather data for New York City. hpd311calls is a subset of call records made to the city's 311 help line about housing issues.\n",
    "\n",
    "In this exercise, you'll use the read_sql() function in pandas to load both tables. read_sql() accepts a string of either a SQL query to run, or a table to load. It also needs a way to connect to the database, like the engine in the provided code.\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "Instructions:\n",
    "\n",
    "<li>Use read_sql() to load the hpd311calls table by name, without any SQL.</li>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "204cc06a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load libraries\n",
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "# Create the database engine\n",
    "engine = create_engine('sqlite:///data.db')\n",
    "\n",
    "# Load hpd311calls without any SQL\n",
    "hpd_calls = pd.read_sql(\"hpd311calls\", engine)\n",
    "\n",
    "# View the first few rows of data\n",
    "print(hpd_calls.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39ef460b",
   "metadata": {},
   "source": [
    "<li> Use read_sql() and a SELECT * ... SQL query to load the entire weather table.</li>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29f8b813",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the database engine\n",
    "engine = create_engine(\"sqlite:///data.db\")\n",
    "\n",
    "# Create a SQL query to load the entire weather table\n",
    "query = \"\"\"\n",
    "  SELECT *\n",
    "  FROM weather;\n",
    "\"\"\"\n",
    "\n",
    "# Load weather with the SQL query\n",
    "weather = pd.read_sql(query, engine)\n",
    "\n",
    "# View the first few rows of data\n",
    "print(weather.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a91283b",
   "metadata": {},
   "source": [
    "## Selecting columns with SQL\n",
    "\n",
    "Datasets can contain columns that are not required for an analysis, like the weather table in data.db does. Some, such as elevation, are redundant, since all observations occurred at the same place, while others contain variables we are not interested in. After making a database engine, you'll write a query to SELECT only the date and temperature columns, and pass both to read_sql() to make a dataframe of high and low temperature readings.\n",
    "\n",
    "pandas has been loaded as pd, and create_engine() has been imported from sqlalchemy.\n",
    "\n",
    "Note: The SQL checker is quite picky about column positions and expects fields to be selected in the specified order.\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "Instructions:\n",
    "\n",
    "\n",
    "<li>Create a database engine for data.db.</li>\n",
    "\n",
    "\n",
    "<li>Write a SQL query that SELECTs the date, tmax, and tmin columns from the weather table.</li>\n",
    "\n",
    "\n",
    "<li>Make a dataframe by passing the query and engine to read_sql() and assign the resulting dataframe to temperatures.</li>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aae3bd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create database engine for data.db\n",
    "engine = create_engine(\"sqlite:///data.db\")\n",
    "\n",
    "# Write query to get date, tmax, and tmin from weather\n",
    "query = \"\"\"\n",
    "SELECT date, \n",
    "       tmax, \n",
    "       tmin\n",
    "  FROM weather;\n",
    "\"\"\"\n",
    "\n",
    "# Make a dataframe by passing query and engine to read_sql()\n",
    "temperatures = pd.read_sql(query, engine)\n",
    "\n",
    "# View the resulting dataframe\n",
    "print(temperatures)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62cc7df8",
   "metadata": {},
   "source": [
    "## Selecting rows\n",
    "\n",
    "SQL WHERE clauses return records whose values meet the given criteria. Passing such a query to read_sql() results in a dataframe loaded with only records we are interested in, so there is less filtering to do later on.\n",
    "\n",
    "The hpd311calls table in data.db has data on calls about various housing issues, from maintenance problems to information requests. In this exercise, you'll use SQL to focus on calls about safety.\n",
    "\n",
    "pandas has been loaded as pd, and a database engine, engine, has been created for data.db.\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "Instructions:\n",
    "\n",
    "\n",
    "<li>Create a query that selects all columns of records in hpd311calls that have 'SAFETY' as their complaint_type.</li>\n",
    "\n",
    "\n",
    "<li>Use read_sql() to query the database and assign the result to the variable safety_calls.</li>\n",
    "\n",
    "\n",
    "<li>Run the last section of code to create a graph of safety call counts in each borough.</li>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a586fca5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create query to get hpd311calls records about safety\n",
    "query = \"\"\"\n",
    "SELECT *\n",
    "FROM hpd311calls\n",
    "WHERE complaint_type = 'SAFETY';\n",
    "\"\"\"\n",
    "\n",
    "# Query the database and assign result to safety_calls\n",
    "safety_calls = pd.read_sql(query, engine)\n",
    "\n",
    "# Graph the number of safety calls by borough\n",
    "call_counts = safety_calls.groupby('borough').unique_key.count()\n",
    "call_counts.plot.barh()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "736d756f",
   "metadata": {},
   "source": [
    "## Filtering on multiple conditions\n",
    "\n",
    "So far, you've selectively imported records that met a single condition, but it's also common to filter datasets on multiple criteria. In this exercise, you'll do just that.\n",
    "\n",
    "The weather table contains daily high and low temperatures and precipitation amounts for New York City. Let's focus on inclement weather, where there was either an inch or more of snow or the high was at or below freezing (32Â° Fahrenheit). To do this, you'll need to build a query that uses the OR operator to look at values in both columns.\n",
    "\n",
    "pandas is loaded as pd, and a database engine, engine, has been created.\n",
    "\n",
    "\n",
    "Instructions:\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "<li>Create a query that selects records in weather where tmax is less than or equal to 32 degrees OR snow is greater than or equal to 1 inch.</li>\n",
    "\n",
    "\n",
    "<li>Use read_sql() to query the database and assign the result to the variable wintry_days.</li>\n",
    "\n",
    "\n",
    "<li>View summary statistics with the describe() method to make sure all records in the dataframe meet the given criteria.</li>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cc6aeb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create query for records with max temps <= 32 or snow >= 1\n",
    "query = \"\"\"\n",
    "  SELECT *\n",
    "  FROM weather\n",
    "  WHERE tmax <= 32 OR snow >= 1;\n",
    "\"\"\"\n",
    "\n",
    "# Query database and assign result to wintry_days\n",
    "wintry_days = pd.read_sql(query, engine)\n",
    "\n",
    "# View summary stats about the temperatures\n",
    "print(wintry_days.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8161634",
   "metadata": {},
   "source": [
    "## Getting distinct values\n",
    "\n",
    "Sometimes an analysis doesn't need every record, but rather unique values in one or more columns. Duplicate values can be removed after loading data into a dataframe, but it can also be done at import with SQL's DISTINCT keyword.\n",
    "\n",
    "Since hpd311calls contains data about housing issues, we would expect most records to have a borough listed. Let's test this assumption by querying unique complaint_type/borough combinations.\n",
    "\n",
    "pandas has been imported as pd, and the database engine has been created as engine.\n",
    "\n",
    "Note: The SQL checker is quite picky about column positions and expects fields to be selected in the specified order.\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "Instructions:\n",
    "\n",
    "\n",
    "<li>Create a query that gets DISTINCT values for borough and complaint_type (in that order) from hpd311calls.</li>\n",
    "\n",
    "\n",
    "<li>Use read_sql() to load the results of the query to a dataframe, issues_and_boros.</li>\n",
    "\n",
    "\n",
    "<li>Print the dataframe to check if the assumption that all issues besides literature requests appear with boroughs listed.</li>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22cfc34e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create query for unique combinations of borough and complaint_type\n",
    "query = \"\"\"\n",
    "  SELECT DISTINCT borough, complaint_type\n",
    "  FROM hpd311calls;\n",
    "\"\"\"\n",
    "\n",
    "# Load results of query to a dataframe\n",
    "issues_and_boros = pd.read_sql(query, engine)\n",
    "\n",
    "# Check assumption about issues and boroughs\n",
    "print(issues_and_boros)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69a4ae04",
   "metadata": {},
   "source": [
    "## Counting in groups\n",
    "\n",
    "In previous exercises, you pulled data from tables, then summarized the resulting dataframes in pandas to create graphs. By using COUNT and GROUP BY in a SQL query, we can pull those summary figures from the database directly.\n",
    "\n",
    "The hpd311calls table has a column, complaint_type, that categorizes call records by issue, such as heating or plumbing. In order to graph call volumes by issue, you'll write a SQL query that COUNTs records by complaint type.\n",
    "\n",
    "pandas has been imported as pd, and the database engine for data.db has been created as engine.\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "Instructions:\n",
    "\n",
    "\n",
    "<li>Create a SQL query that gets the complaint_type column and counts of all records from hpd311calls, grouped by complaint_type.</li>\n",
    "\n",
    "\n",
    "<li>Create a dataframe with read_sql() of call counts by issue, calls_by_issue.</li>\n",
    "\n",
    "\n",
    "<li>Run the last section of code to graph the number of calls for each housing issue.</li>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffaba1cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create query to get call counts by complaint_type\n",
    "query = \"\"\"\n",
    "  SELECT complaint_type, COUNT(*)\n",
    "  FROM hpd311calls\n",
    "  GROUP BY complaint_type\n",
    "\"\"\"\n",
    "\n",
    "# Create dataframe of call counts by issue\n",
    "calls_by_issue = pd.read_sql(query, engine)\n",
    "\n",
    "# Graph the number of calls for each housing issue\n",
    "calls_by_issue.plot.barh(x=\"complaint_type\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00bba7d9",
   "metadata": {},
   "source": [
    "## Working with aggregate functions\n",
    "\n",
    "If a table contains data with higher granularity than is needed for an analysis, it can make sense to summarize the data with SQL aggregate functions before importing it. For example, if you have data of flood event counts by month but precipitation data by day, you may decide to SUM precipitation by month.\n",
    "\n",
    "The weather table contains daily readings for four months. In this exercise, you'll practice summarizing weather by month with the MAX, MIN, and SUM functions.\n",
    "\n",
    "pandas has been loaded as pd, and a database engine, engine, has been created.\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "Instructions:\n",
    "\n",
    "\n",
    "<li>Create a query to pass to read_sql() that will get months and the MAX value of tmax by monthfrom weather.</li>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f798c02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a query to get month and max tmax by month\n",
    "query = \"\"\"\n",
    "  SELECT month, MAX(tmax)\n",
    "  FROM weather\n",
    "  GROUP BY month\n",
    "\"\"\"\n",
    "\n",
    "# Get dataframe of monthly weather stats\n",
    "weather_by_month = pd.read_sql(query, engine)\n",
    "\n",
    "# View weather stats by month\n",
    "print(weather_by_month)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed1162e3",
   "metadata": {},
   "source": [
    "<li>Modify the query to also get the MIN tmin value for each month.</li>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ee4d04a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a query to get month, max tmax, and min tmin by month\n",
    "query = \"\"\"\n",
    "  SELECT month, MAX(tmax), MIN(tmin)\n",
    "  FROM weather \n",
    "  GROUP BY month;\n",
    "\"\"\"\n",
    "\n",
    "# Get dataframe of monthly weather stats\n",
    "weather_by_month = pd.read_sql(query, engine)\n",
    "\n",
    "# View weather stats by month\n",
    "print(weather_by_month)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a787dd99",
   "metadata": {},
   "source": [
    "<li>Modify the query to also get the total precipitation (prcp) for each month.</li>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9554d8de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create query to get temperature and precipitation by month\n",
    "query = \"\"\"\n",
    "  SELECT month, MAX(tmax), MIN(tmin), SUM(prcp)\n",
    "  FROM weather \n",
    "  GROUP BY month;\n",
    "\"\"\"\n",
    "\n",
    "# Get dataframe of monthly weather stats\n",
    "weather_by_month = pd.read_sql(query, engine)\n",
    "\n",
    "# View weather stats by month\n",
    "print(weather_by_month)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52d78fa0",
   "metadata": {},
   "source": [
    "## Joining tables\n",
    "\n",
    "Tables in relational databases usually have key columns of unique record identifiers. This lets us build pipelines that combine tables using SQL's JOIN operation, instead of having to combine data after importing it.\n",
    "\n",
    "The records in hpd311calls often concern issues, like leaks or heating problems, that are exacerbated by weather conditions. In this exercise, you'll join weather data to call records along their common date columns to get everything in one dataframe. You can assume these columns have the same data type.\n",
    "\n",
    "pandas is loaded as pd, and the database engine, engine, has been created.\n",
    "\n",
    "Note: The SQL checker is picky about join table order -- it expects specific tables on the left and the right.\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "Instructions:\n",
    "\n",
    "\n",
    "<li>Complete the query to join weather to hpd311calls by their date and created_date columns, respectively.</li>\n",
    "\n",
    "\n",
    "<li>Query the database and assign the resulting dataframe to calls_with_weather.</li>\n",
    "\n",
    "\n",
    "<li>Print the first few rows of calls_with_weather to confirm all columns were joined.</li>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0779c5cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query to join weather to call records by date columns\n",
    "query = \"\"\"\n",
    "  SELECT * \n",
    "  FROM hpd311calls\n",
    "  JOIN weather \n",
    "  ON hpd311calls.created_date = weather.date;\n",
    "\"\"\"\n",
    "\n",
    "# Create dataframe of joined tables\n",
    "calls_with_weather = pd.read_sql(query, engine)\n",
    "\n",
    "# View the dataframe to make sure all columns were joined\n",
    "print(calls_with_weather.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "401ec422",
   "metadata": {},
   "source": [
    "## Joining and filtering\n",
    "\n",
    "Just as you might not always want all the data in a single table, you might not want all columns and rows that result from a JOIN. In this exercise, you'll use SQL to refine a data import.\n",
    "\n",
    "Weather exacerbates some housing problems more than others. Your task is to focus on water leak reports in hpd311calls and assemble a dataset that includes the day's precipitation levels from weather to see if there is any relationship between the two. The provided SQL gets all columns in hpd311calls, but you'll need to modify it to get the necessary weather column and filter rows with a WHERE clause.\n",
    "\n",
    "pandas is loaded as pd, and the database engine, engine, has been created.\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "Instructions:\n",
    "\n",
    "\n",
    "<li>Complete query to get the prcp column in weather and join weather to hpd311calls on their date and created_date columns, respectively.</li>\n",
    "\n",
    "\n",
    "<li>Use read_sql() to load the results of the query into the leak_calls dataframe.</li>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27b42797",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query to get hpd311calls and precipitation values\n",
    "query = \"\"\"\n",
    "  SELECT hpd311calls.*, weather.prcp\n",
    "  FROM hpd311calls\n",
    "  JOIN weather\n",
    "  ON hpd311calls.created_date = weather.date;\"\"\"\n",
    "\n",
    "# Load query results into the leak_calls dataframe\n",
    "leak_calls = pd.read_sql(query, engine)\n",
    "\n",
    "# View the dataframe\n",
    "print(leak_calls.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32df907e",
   "metadata": {},
   "source": [
    "<li>Modify query to get only rows that have 'WATER LEAK' as their complaint_type.</li>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45c724ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query to get water leak calls and daily precipitation\n",
    "query = \"\"\"\n",
    "SELECT hpd311calls.*, weather.prcp\n",
    "  FROM hpd311calls\n",
    "  JOIN weather\n",
    "    ON hpd311calls.created_date = weather.date\n",
    "  WHERE hpd311calls.complaint_type = 'WATER LEAK';\"\"\"\n",
    "\n",
    "# Load query results into the leak_calls dataframe\n",
    "leak_calls = pd.read_sql(query, engine)\n",
    "\n",
    "# View the dataframe\n",
    "print(leak_calls.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0897b20b",
   "metadata": {},
   "source": [
    "## Joining, filtering, and aggregating\n",
    "\n",
    "In this exercise, you'll use what you've learned to assemble a dataset to investigate how the number of heating complaints to New York City's 311 line varies with temperature.\n",
    "\n",
    "In addition to the hpd311calls table, data.db has a weather table with daily high and low temperature readings for NYC. We want to get each day's count of heat/hot water calls with temperatures joined in. This can be done in one query, which we'll build in parts.\n",
    "\n",
    "In part one, we'll get just the data we want from hpd311calls. Then, in part two, we'll modify the query to join in weather data.\n",
    "\n",
    "pandas has been imported as pd, and the database engine has been created as engine.\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "Instructions:\n",
    "\n",
    "\n",
    "<li>Complete the query to get created_date and counts of records whose complaint_type is HEAT/HOT WATER from hpd311calls by date.</li>\n",
    "\n",
    "\n",
    "<li>Create a dataframe,df, containing the results of the query.</li>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ed82ff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query to get heat/hot water call counts by created_date\n",
    "query = \"\"\"\n",
    "SELECT hpd311calls.created_date, COUNT(*)\n",
    "FROM hpd311calls\n",
    "WHERE hpd311calls.complaint_type = 'HEAT/HOT WATER'\n",
    "GROUP BY hpd311calls.created_date;\n",
    "\"\"\"\n",
    "\n",
    "# Query database and save results as df\n",
    "df = pd.read_sql(query, engine)\n",
    "\n",
    "# View first 5 records\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef43bb85",
   "metadata": {},
   "source": [
    "<li>Modify the query to join tmax and tmin from the weather table. (There is only one record per date in weather, so we do not need SQL's MAX and MIN functions here.) Join the tables on created_date in hpd311calls and date in weather.</li>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6b2a2af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modify query to join tmax and tmin from weather by date\n",
    "query = \"\"\"\n",
    "SELECT hpd311calls.created_date, \n",
    "\t   COUNT(*), \n",
    "       weather.tmax,\n",
    "       weather.tmin\n",
    "  FROM hpd311calls \n",
    "       JOIN weather\n",
    "       ON hpd311calls.created_date = weather.date\n",
    " WHERE hpd311calls.complaint_type = 'HEAT/HOT WATER' \n",
    " GROUP BY hpd311calls.created_date;\n",
    " \"\"\"\n",
    "\n",
    "# Query database and save results as df\n",
    "df = pd.read_sql(query, engine)\n",
    "\n",
    "# View first 5 records\n",
    "print(df.head())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
