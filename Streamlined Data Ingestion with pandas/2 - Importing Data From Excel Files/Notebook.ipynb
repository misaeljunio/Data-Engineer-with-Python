{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "40614a3d",
   "metadata": {},
   "source": [
    "## Get data from a spreadsheet\n",
    "\n",
    "In this exercise, you'll create a dataframe from a \"base case\" Excel file: one with a single sheet of tabular data. The `fcc_survey.xlsx` file here has a sample of responses from FreeCodeCamp's annual New Developer Survey. This survey asks participants about their demographics, education, work and home life, plus questions about how they're learning to code. Let's load all of it.\n",
    "\n",
    "`pandas` has not been pre-loaded in this exercise, so you'll need to import it yourself before using `read_excel()` to load the spreadsheet.\n",
    "\n",
    "---\n",
    "\n",
    "Instructions:\n",
    "\n",
    "1. Load the `pandas` library as `pd`.\n",
    "\n",
    "\n",
    "2. Read in `fcc_survey.xlsx` and assign it to the variable `survey_responses`.\n",
    "\n",
    "\n",
    "3. Print the first few records of `survey_responses`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8495f29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pandas as pd\n",
    "import pandas as pd\n",
    "\n",
    "# Read spreadsheet and assign it to survey_responses\n",
    "survey_responses = pd.read_excel(\"fcc_survey.xlsx\")\n",
    "\n",
    "# View the head of the dataframe\n",
    "print(survey_responses.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f8f7bd3",
   "metadata": {},
   "source": [
    "## Load a portion of a spreadsheet\n",
    "\n",
    "Spreadsheets meant to be read by people often have multiple tables, e.g., a small business might keep an inventory workbook with tables for different product types on a single sheet. Even tabular data may have header rows of metadata, like the New Developer Survey data here. While the metadata is useful, we don't want it in a dataframe. You'll use `read_excel()`'s `skiprows` keyword to get just the data. You'll also create a string to pass to `usecols` to get only columns AD and AW through BA, about future job goals.\n",
    "\n",
    "`pandas` has been imported as `pd`.\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "Instructions:\n",
    "\n",
    "\n",
    "1. Create a single string, `col_string`, specifying that `pandas` should load column `AD` and the range `AW` through `BA`.\n",
    "\n",
    "\n",
    "2. Load `'fcc_survey_headers.xlsx'`, setting `skiprows` and `usecols` to skip the first two rows of metadata and get only the columns in `col_string`.\n",
    "\n",
    "\n",
    "3. View the selected column names in the resulting dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a435872",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create string of lettered columns to load\n",
    "col_string = \"AD, AW:BA\"\n",
    "\n",
    "# Load data with skiprows and usecols set\n",
    "survey_responses = pd.read_excel(\"fcc_survey_headers.xlsx\",\n",
    "                                skiprows=2,\n",
    "                                usecols=col_string)\n",
    "\n",
    "# View the names of the columns selected\n",
    "print(survey_responses.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ecde84c",
   "metadata": {},
   "source": [
    "## Select a single sheet\n",
    "\n",
    "An Excel workbook may contain multiple sheets of related data. The New Developer Survey response workbook has sheets for different years. Because `read_excel()` loads only the first sheet by default, you've already gotten survey responses for 2016. Now, you'll create a dataframe of 2017 responses using `read_excel()`'s `sheet_name` argument in a couple different ways.\n",
    "\n",
    "`pandas` has been imported as `pd`.\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "Instructions:\n",
    "\n",
    "\n",
    "1. Create a dataframe from the second workbook sheet by passing the sheet's position to `sheet_name`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4f32eb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create df from second worksheet by referencing its position\n",
    "responses_2017 = pd.read_excel(\"fcc_survey.xlsx\",\n",
    "                               1)\n",
    "\n",
    "# Graph where people would like to get a developer job\n",
    "job_prefs = responses_2017.groupby(\"JobPref\").JobPref.count()\n",
    "job_prefs.plot.barh()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f861312",
   "metadata": {},
   "source": [
    "2. Create a dataframe from the `2017` sheet by providing the sheet's name to `read_excel()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a0147e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create df from second worksheet by referencing its name\n",
    "responses_2017 = pd.read_excel(\"fcc_survey.xlsx\",\n",
    "                               \"2017\")\n",
    "\n",
    "# Graph where people would like to get a developer job\n",
    "job_prefs = responses_2017.groupby(\"JobPref\").JobPref.count()\n",
    "job_prefs.plot.barh()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "675eef6a",
   "metadata": {},
   "source": [
    "## Select multiple sheets\n",
    "\n",
    "So far, you've read Excel files one sheet at a time, which lets you customize import arguments for each sheet. But if an Excel file has some sheets that you want loaded with the same parameters, you can get them in one go by passing a list of their names or indices to `read_excel()`'s `sheet_name` keyword. To get them all, pass `None`. You'll practice both methods to get data from `fcc_survey.xlsx`, which has multiple sheets of similarly-formatted data.\n",
    "\n",
    "`pandas` has been loaded as `pd`.\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "Instructions:\n",
    "\n",
    "\n",
    "1. Load both the `2016` and `2017` sheets by name with a list and one call to `read_excel()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbd20225",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load both the 2016 and 2017 sheets by name\n",
    "all_survey_data = pd.read_excel(\"fcc_survey.xlsx\",\n",
    "                                sheet_name = [\"2016\", \"2017\"])\n",
    "\n",
    "# View the data type of all_survey_data\n",
    "print(type(all_survey_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2b1a163",
   "metadata": {},
   "source": [
    "2. Load the `2016` sheet by its position (`0`) and `2017` by name. Note the sheet names in the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f053929",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load all sheets in the Excel file\n",
    "all_survey_data = pd.read_excel(\"fcc_survey.xlsx\",\n",
    "                                sheet_name = [0, \"2017\"])\n",
    "\n",
    "# View the sheet names in all_survey_data\n",
    "print(all_survey_data.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fe392da",
   "metadata": {},
   "source": [
    "3. Load all sheets in the Excel file without listing them all."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c659e74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load all sheets in the Excel file\n",
    "all_survey_data = pd.read_excel(\"fcc_survey.xlsx\",\n",
    "                                sheet_name = None)\n",
    "\n",
    "# View the sheet names in all_survey_data\n",
    "print(all_survey_data.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b264ce15",
   "metadata": {},
   "source": [
    "## Work with multiple spreadsheets\n",
    "\n",
    "Workbooks meant primarily for human readers, not machines, may store data about a single subject across multiple sheets. For example, a file may have a different sheet of transactions for each region or year in which a business operated.\n",
    "\n",
    "The FreeCodeCamp New Developer Survey file is set up similarly, with samples of responses from different years in different sheets. Your task here is to compile them in one dataframe for analysis.\n",
    "\n",
    "`pandas` has been imported as `pd`. All sheets have been read into the ordered dictionary `responses`, where sheet names are keys and dataframes are values, so you can get dataframes with the `values()` method.\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "Instructions:\n",
    "\n",
    "\n",
    "1. Create an empty dataframe, `all_responses`.\n",
    "\n",
    "\n",
    "2. Set up a `for` loop to iterate through the values in the `responses` dictionary.\n",
    "\n",
    "\n",
    "3. Append each dataframe to `all_responses` and reassign the result to the same variable name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50a41381",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an empty dataframe\n",
    "all_responses = pd.DataFrame()\n",
    "\n",
    "# Set up for loop to iterate through values in responses\n",
    "for df in responses.values():\n",
    "  # Print the number of rows being added\n",
    "  print(\"Adding {} rows\".format(df.shape[0]))\n",
    "  # Append df to all_responses, assign result\n",
    "  all_responses = all_responses.append(df)\n",
    "\n",
    "# Graph employment statuses in sample\n",
    "counts = all_responses.groupby(\"EmploymentStatus\").EmploymentStatus.count()\n",
    "counts.plot.barh()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4374e47",
   "metadata": {},
   "source": [
    "## Set Boolean columns\n",
    "\n",
    "Datasets may have columns that are most accurately modeled as Boolean values. However, `pandas` usually loads these as floats by default, since defaulting to Booleans may have undesired effects like turning NA values into `True`s.\n",
    "\n",
    "`fcc_survey_subset.xlsx` contains a string ID column and several True/False columns indicating financial stressors. You'll evaluate which non-ID columns have no NA values and therefore can be set as Boolean, then tell `read_excel()` to load them as such with the `dtype` argument.\n",
    "\n",
    "`pandas` is loaded as `pd`.\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "Instructions:\n",
    "\n",
    "\n",
    "1. Count NA values in each column of `survey_data` with `isna()` and `sum()`. Note which columns besides `ID.x`, if any, have zero NAs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6e85444",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data\n",
    "survey_data = pd.read_excel(\"fcc_survey_subset.xlsx\")\n",
    "\n",
    "# Count NA values in each column\n",
    "print(survey_data.isna().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb2b1e9f",
   "metadata": {},
   "source": [
    "2. Set `read_excel()`'s `dtype` argument to load the `HasDebt` column as Boolean data.\n",
    "\n",
    "\n",
    "3. Supply the Boolean column name to the print statement to view financial burdens by group."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9664b7ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set dtype to load appropriate column(s) as Boolean data\n",
    "survey_data = pd.read_excel(\"fcc_survey_subset.xlsx\",\n",
    "                            dtype={\n",
    "                                \"HasDebt\": bool\n",
    "                            })\n",
    "\n",
    "# View financial burdens by Boolean group\n",
    "print(survey_data.groupby(\"HasDebt\").sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "972281f8",
   "metadata": {},
   "source": [
    "## Set custom true/false values\n",
    "\n",
    "In Boolean columns, `pandas` automatically recognizes certain values, like \"TRUE\" and 1, as `True`, and others, like \"FALSE\" and 0, as `False`. Some datasets, like survey data, can use unrecognized values, such as \"Yes\" and \"No\".\n",
    "\n",
    "For practice purposes, some Boolean columns in the New Developer Survey have been coded this way. You'll make sure they're properly interpreted with the help of the `true_values` and `false_values` arguments.\n",
    "\n",
    "`pandas` is loaded as `pd`. You can assume the columns you are working with have no missing values.\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "Instructions:\n",
    "\n",
    "\n",
    "1. Load the Excel file, specifying `\"Yes\"` as a true value and `\"No\"` as a false value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "226932e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load file with Yes as a True value and No as a False value\n",
    "survey_subset = pd.read_excel(\"fcc_survey_yn_data.xlsx\",\n",
    "                              dtype={\"HasDebt\": bool,\n",
    "                              \"AttendedBootCampYesNo\": bool},\n",
    "                              true_values=[\"Yes\"],\n",
    "                              false_values=[\"No\"])\n",
    "\n",
    "# View the data\n",
    "print(survey_subset.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1391dc15",
   "metadata": {},
   "source": [
    "## Parse simple dates\n",
    "\n",
    "`pandas` does not infer that columns contain datetime data; it interprets them as object or string data unless told otherwise. Correctly modeling datetimes is easy when they are in a standard format -- we can use the `parse_dates` argument to tell `read_excel()` to read columns as datetime data.\n",
    "\n",
    "The New Developer Survey responses contain some columns with easy-to-parse timestamps. In this exercise, you'll make sure they're the right data type.\n",
    "\n",
    "`pandas` has been loaded as `pd`.\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "Instructions:\n",
    "\n",
    "\n",
    "1. Load `fcc_survey.xlsx`, making sure that the `Part1StartTime` column is parsed as datetime data.\n",
    "\n",
    "\n",
    "2. View the first few values of the survey_data.Part1StartTime to make sure it contains datetimes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53a3b9ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load file, with Part1StartTime parsed as datetime data\n",
    "survey_data = pd.read_excel(\"fcc_survey.xlsx\",\n",
    "                            parse_dates=[\"Part1StartTime\"])\n",
    "\n",
    "# Print first few values of Part1StartTime\n",
    "print(survey_data.Part1StartTime.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5591dcc",
   "metadata": {},
   "source": [
    "## Get datetimes from multiple columns\n",
    "\n",
    "Sometimes, datetime data is split across columns. A dataset might have a date and a time column, or a date may be split into year, month, and day columns.\n",
    "\n",
    "A column in this version of the survey data has been split so that dates are in one column, `Part2StartDate`, and times are in another, `Part2StartTime`. Your task is to use `read_excel()`'s `parse_dates` argument to combine them into one datetime column with a new name.\n",
    "\n",
    "`pandas` has been imported as `pd`.\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "Instructions:\n",
    "\n",
    "\n",
    "1. Create a dictionary, `datetime_cols` indicating that the new column `Part2Start` should consist of `Part2StartDate` and `Part2StartTime`.\n",
    "\n",
    "\n",
    "2. Load the survey response file, supplying the dictionary to the `parse_dates` argument to create a new `Part2Start` column.\n",
    "\n",
    "\n",
    "3. View summary statistics about the new `Part2Start` column with the `describe()` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d991db41",
   "metadata": {},
   "outputs": [],
   "source": [
    "    # Create dict of columns to combine into new datetime column\n",
    "datetime_cols = {\"Part2Start\": [\"Part2StartDate\", \"Part2StartTime\"]}\n",
    "\n",
    "\n",
    "# Load file, supplying the dict to parse_dates\n",
    "survey_data = pd.read_excel(\"fcc_survey_dts.xlsx\",\n",
    "                            parse_dates=datetime_cols)\n",
    "\n",
    "# View summary statistics about Part2Start\n",
    "print(survey_data.Part2Start.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c5154cf",
   "metadata": {},
   "source": [
    "## Parse non-standard date formats\n",
    "\n",
    "So far, you've parsed dates that `pandas` could interpret automatically. But if a date is in a non-standard format, like 19991231 for December 31, 1999, it can't be parsed at the import stage. Instead, use `pd.to_datetime()` to convert strings to dates after import.\n",
    "\n",
    "The New Developer Survey data has been loaded as `survey_data` but contains an unparsed datetime field. We'll use `to_datetime()` to convert it, passing in the column to convert and a string representing the date format used.\n",
    "\n",
    "For more on date format codes, see this reference. Some common codes are year (`%Y`), month (`%m`), day (`%d`), hour (`%H`), minute (`%M`), and second (`%S`).\n",
    "\n",
    "`pandas` has been imported as `pd`.\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "1. Parse `Part2EndTime` using `pd.to_datetime()`, the `format` keyword argument, and the format string you just identified. Assign the result back to the `Part2EndTime` column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e15942b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parse datetimes and assign result back to Part2EndTime\n",
    "survey_data[\"Part2EndTime\"] = pd.to_datetime(survey_data[\"Part2EndTime\"],\n",
    "                                   format=\"%m%d%Y %H:%M:%S\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3be0a192",
   "metadata": {},
   "source": [
    "2. Print the head of `Part2EndTime` to confirm the column now contains datetime values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99e0ab10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parse datetimes and assign result back to Part2EndTime\n",
    "survey_data[\"Part2EndTime\"] = pd.to_datetime(survey_data[\"Part2EndTime\"], \n",
    "                                             format=\"%m%d%Y %H:%M:%S\")\n",
    "\n",
    "# Print first few values of Part2EndTime\n",
    "print(survey_data[\"Part2EndTime\"].head())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
