{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f39a4191",
   "metadata": {},
   "source": [
    "## Create a test class\n",
    "\n",
    "Test classes are containers inside test modules. They help separate tests for different functions within the test module, and serve as a structuring tool in the pytest framework.\n",
    "\n",
    "Test classes are written in CamelCase e.g. TestMyFunction as opposed to tests, which are written using underscores e.g. test_something().\n",
    "\n",
    "You met the function split_into_training_and_testing_sets() in Chapter 2, and wrote some tests for it. One of these tests was called test_on_one_row() and it checked if the function raises a ValueError when passed a NumPy array with only one row.\n",
    "\n",
    "In this exercise you are going to create a test class for this function. This test class will hold the test test_on_one_row().\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "Instructions:\n",
    "\n",
    "\n",
    "- Declare the test class for the function split_into_training_and_testing_sets(), making sure to give it a name that follows the standard naming convention.\n",
    "\n",
    "\n",
    "- Fill in the mandatory argument in the test test_on_one_row()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c47612a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytest\n",
    "import numpy as np\n",
    "\n",
    "from models.train import split_into_training_and_testing_sets\n",
    "\n",
    "# Declare the test class\n",
    "class TestSplitIntoTrainingAndTestingSets(object):\n",
    "    # Fill in with the correct mandatory argument\n",
    "    def test_on_one_row(self):\n",
    "        test_argument = np.array([[1382.0, 390167.0]])\n",
    "        with pytest.raises(ValueError) as exc_info:\n",
    "            split_into_training_and_testing_sets(test_argument)\n",
    "        expected_error_msg = \"Argument data_array must have at least 2 rows, it actually has just 1\"\n",
    "        assert exc_info.match(expected_error_msg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f568fe9",
   "metadata": {},
   "source": [
    "## Running test classes\n",
    "\n",
    "When you ran the !pytest command in the last exercise, the test test_on_six_rows() failed. This is a test for the function split_into_training_and_testing_sets(). This means that this function is broken.\n",
    "\n",
    "Short recap in case you forgot: this function takes a NumPy array containing housing area and prices as argument. The function randomly splits the argument array into training and testing arrays in the ratio 3:1, and returns the resulting arrays in a tuple.\n",
    "\n",
    "A quick look revealed that during the code update, someone inadvertently changed the split from 3:1 to 9:1. This has to be changed back and the unit tests for the function, which now lives in the test class TestSplitIntoTrainingAndTestingSets, needs to be run again. Are you up to the challenge?\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "Instructions:\n",
    "\n",
    "\n",
    "- Fill in with a float between 0 and 1 so that num_training is approximately of the number of rows in data_array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae026efe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def split_into_training_and_testing_sets(data_array):\n",
    "    dim = data_array.ndim\n",
    "    if dim != 2:\n",
    "        raise ValueError(\"Argument data_array must be two dimensional. Got {0} dimensional array instead!\".format(dim))\n",
    "    num_rows = data_array.shape[0]\n",
    "    if num_rows < 2:\n",
    "        raise ValueError(\"Argument data_array must have at least 2 rows, it actually has just {0}\".format(num_rows))\n",
    "    # Fill in with the correct float\n",
    "    num_training = int(0.75 * data_array.shape[0])\n",
    "    permuted_indices = np.random.permutation(data_array.shape[0])\n",
    "    return data_array[permuted_indices[:num_training], :], data_array[permuted_indices[num_training:], :]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36da351f",
   "metadata": {},
   "source": [
    "## Mark a test class as expected to fail\n",
    "\n",
    "A new function model_test() is being developed and it returns the accuracy of a given linear regression model on a testing dataset. Test Driven Development (TDD) is being used to implement it. The procedure is: write tests first and then implement the function.\n",
    "\n",
    "A test class TestModelTest has been created within the test module models/test_train.py. In the test class, there are two unit tests called test_on_linear_data() and test_on_one_dimensional_array(). But the function model_test() has not been implemented yet.\n",
    "\n",
    "Throughout this exercise, pytest and numpy as np will be imported for you.\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "Instructions:\n",
    "\n",
    "\n",
    "- Mark the whole test class TestModelTest as \"expected to fail\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9664624",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mark the whole test class as \"expected to fail\"\n",
    "@pytest.mark.xfail\n",
    "class TestModelTest(object):\n",
    "    def test_on_linear_data(self):\n",
    "        test_input = np.array([[1.0, 3.0], [2.0, 5.0], [3.0, 7.0]])\n",
    "        expected = 1.0\n",
    "        actual = model_test(test_input, 2.0, 1.0)\n",
    "        message = \"model_test({0}) should return {1}, but it actually returned {2}\".format(test_input, expected, actual)\n",
    "        assert actual == pytest.approx(expected), message\n",
    "        \n",
    "    def test_on_one_dimensional_array(self):\n",
    "        test_input = np.array([1.0, 2.0, 3.0, 4.0])\n",
    "        with pytest.raises(ValueError) as exc_info:\n",
    "            model_test(test_input, 1.0, 1.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f31709a9",
   "metadata": {},
   "source": [
    "- Add the following reason for the expected failure: \"Using TDD, model_test() has not yet been implemented\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2224f1a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a reason for the expected failure\n",
    "@pytest.mark.xfail(reason = \"Using TDD, model_test() has not yet been implemented\")\n",
    "class TestModelTest(object):\n",
    "    def test_on_linear_data(self):\n",
    "        test_input = np.array([[1.0, 3.0], [2.0, 5.0], [3.0, 7.0]])\n",
    "        expected = 1.0\n",
    "        actual = model_test(test_input, 2.0, 1.0)\n",
    "        message = \"model_test({0}) should return {1}, but it actually returned {2}\".format(test_input, expected, actual)\n",
    "        assert actual == pytest.approx(expected), message\n",
    "        \n",
    "    def test_on_one_dimensional_array(self):\n",
    "        test_input = np.array([1.0, 2.0, 3.0, 4.0])\n",
    "        with pytest.raises(ValueError) as exc_info:\n",
    "            model_test(test_input, 1.0, 1.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0efbe925",
   "metadata": {},
   "source": [
    "## Mark a test as conditionally skipped\n",
    "\n",
    "In Python 2, there was a built-in function called xrange(). In Python 3, xrange() was removed. Therefore, if any test uses xrange(), it's going to fail with a NameError in Python 3.\n",
    "\n",
    "Remember the function get_data_as_numpy_array()? You saw it in Chapter 2. It converted data in a preprocessed data file into a NumPy array.\n",
    "\n",
    "range() has been deliberately replaced with the obsolete xrange() in the function. Evil laughter! But no worries, it will be changed back after you're done with this exercise.\n",
    "\n",
    "You wrote a test called test_on_clean_file() for this function. This test currently resides in a test class TestGetDataAsNumpyArray inside the test module features/test_as_numpy.py.\n",
    "\n",
    "pytest, numpy as np and get_data_as_numpy_array() has been imported for you.\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "Instructions:\n",
    "\n",
    "\n",
    "- Import the sys module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ae2f918",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the sys module\n",
    "import sys"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "510b74f8",
   "metadata": {},
   "source": [
    "- Mark the test test_on_clean_file() as skipped if the Python version is greater than 2.7."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80f2e379",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the sys module\n",
    "import sys\n",
    "\n",
    "class TestGetDataAsNumpyArray(object):\n",
    "    # Mark as skipped if Python version is greater than 2.7\n",
    "    @pytest.mark.skipif(sys.version_info > (2, 7))\n",
    "    def test_on_clean_file(self):\n",
    "        expected = np.array([[2081.0, 314942.0],\n",
    "                             [1059.0, 186606.0],\n",
    "                             [1148.0, 206186.0]\n",
    "                             ]\n",
    "                            )\n",
    "        actual = get_data_as_numpy_array(\"example_clean_data.txt\", num_columns=2)\n",
    "        message = \"Expected return value: {0}, Actual return value: {1}\".format(expected, actual)\n",
    "        assert actual == pytest.approx(expected), message"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d51d8fb",
   "metadata": {},
   "source": [
    "- Add the following reason for skipping the test: \"Works only on Python 2.7 or lower\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "994ea6ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the sys module\n",
    "import sys\n",
    "\n",
    "class TestGetDataAsNumpyArray(object):\n",
    "    # Add a reason for skipping the test\n",
    "    @pytest.mark.skipif(sys.version_info > (2, 7), reason = \"Works only on Python 2.7 or lower\")\n",
    "    def test_on_clean_file(self):\n",
    "        expected = np.array([[2081.0, 314942.0],\n",
    "                             [1059.0, 186606.0],\n",
    "                             [1148.0, 206186.0]\n",
    "                             ]\n",
    "                            )\n",
    "        actual = get_data_as_numpy_array(\"example_clean_data.txt\", num_columns=2)\n",
    "        message = \"Expected return value: {0}, Actual return value: {1}\".format(expected, actual)\n",
    "        assert actual == pytest.approx(expected), message"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
